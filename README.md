# Submission 1: Hoax Detection
Nama: Harry Mardika

Username dicoding: hkacode

| | **Deskripsi** |
| ----------- | ----------- |
| **Dataset** | [Indonesia False News (Hoax) Dataset](https://www.kaggle.com/datasets/muhammadghazimuharam/indonesiafalsenews/data) |
| **Masalah** | Hoax atau berita palsu merupakan masalah yang signifikan dalam konteks informasi digital saat ini. Berita palsu dapat menyebabkan ketidakpercayaan publik, mempengaruhi opini dan keputusan, serta bahkan dapat memicu konflik sosial. Dalam proyek ini, masalah yang diangkat adalah bagaimana mengidentifikasi dan mengklasifikasikan berita palsu dengan tepat menggunakan pendekatan machine learning. Tantangan utama meliputi keberagaman gaya penulisan, variasi topik, dan strategi manipulatif yang digunakan oleh pembuat berita palsu. |
| **Solusi Machine Learning** | Solusi yang diusulkan adalah menggunakan pendekatan deep learning dengan arsitektur Convolutional Neural Network (CNN). CNN dipilih karena kemampuannya dalam mengekstrak fitur spasial dari data berbasis grid, seperti teks dalam kalimat. Model ini akan dilatih untuk mengenali pola-pola yang umumnya terkait dengan berita palsu, seperti penggunaan kata-kata emosional, judul sensasional, atau konten yang tidak kredibel secara faktual. Penggunaan deep learning diharapkan dapat meningkatkan akurasi dan generalisasi model dalam mendeteksi berita palsu. |
| **Metode Pengolahan** | Metode pengolahan data yang digunakan dalam proyek ini bertujuan untuk membersihkan dan mempersiapkan teks berita sebelum dimasukkan ke dalam model machine learning. Langkah-langkah pengolahan data meliputi: <br> 1. **Lowercasing**: Semua teks diubah menjadi huruf kecil untuk konsistensi dalam pemrosesan teks. 2. <br> **Penghapusan Tanda Baca**: Tanda baca seperti tanda kutip tunggal dan ganda dihapus dari teks untuk menghilangkan potensi gangguan dalam analisis. <br> 3. **Penghapusan Karakter Khusus**: Karakter khusus yang tidak relevan atau tidak diinginkan dihapus dari teks menggunakan ekspresi regular. <br> 4. **Penghapusan Spasi Ekstra**: Spasi yang berlebihan dihapus untuk memastikan format teks yang bersih dan konsisten. <br> 5. **Pemangkasan Spasi**: Spasi di awal dan akhir teks dipangkas agar tidak mempengaruhi hasil pemrosesan. <br> <br>  Metode pengolahan ini bertujuan untuk mempersiapkan teks berita sehingga model machine learning dapat dengan efektif mengenali pola-pola yang relevan dalam deteksi berita palsu. Dengan membersihkan dan merapihkan teks secara konsisten, diharapkan kualitas data yang masuk ke model dapat ditingkatkan, menghasilkan hasil klasifikasi yang lebih akurat.|
| **Arsitektur Model** | Arsitektur model yang digunakan terdiri dari beberapa lapisan, yaitu: <br> 1. **Input Layer**: Menerima input teks dalam bentuk string. <br> 2. **Text Vectorization Layer**: Mengubah teks menjadi token numerik dengan TextVectorization layer dari Keras. <br> 3. **Embedding Layer**: Mengubah token numerik menjadi vektor dimensi yang lebih tinggi untuk menangkap makna kontekstual dari token. <br> 4. **Convolutional Layer**: Menggunakan lapisan Conv1D untuk menangkap fitur spasial dari teks, membantu dalam mendeteksi pola-pola umum pada kalimat-kalimat yang mengandung hoax. <br> 5. **Global Max Pooling Layer**: Mengambil nilai maksimum dari fitur yang dideteksi untuk setiap filter, mengurangi dimensi data dan fokus pada fitur yang paling menonjol. <br> 6. **Dense Layer 1**: Menggunakan lapisan fully connected untuk menggabungkan fitur-fitur yang diekstraksi dari lapisan sebelumnya. <br> 7. **Dropout Layer 1**: Pada lapisan Dense pertama setelah ekstraksi fitur dari lapisan sebelumnya, Dropout membantu dalam menghindari ketergantungan yang berlebihan pada fitur-fitur tertentu dan meningkatkan generalisasi model terhadap data uji. <br> 8. **Dense Layer 2**: Lapisan Dense kedua mengambil fitur-fitur yang telah diolah dan diekstraksi sebelumnya dan memproyeksikannya ke ruang fitur yang lebih tinggi lagi. <br> 9. **Dropout Layer 2**: Dropout kedua diaplikasikan setelah lapisan Dense kedua, menggunakan konsep yang sama dengan Dropout pertama. Ini membantu memastikan bahwa model tidak terlalu bergantung pada pola atau fitur-fitur tertentu yang mungkin hanya muncul dalam data pelatihan tetapi tidak umum dalam data uji atau penggunaan di dunia nyata. <br> 10. **Output Layer**: Menggunakan lapisan Dense dengan aktivasi sigmoid untuk menghasilkan probabilitas antara 0 (berita palsu atau hoax) dan 1 (berita asli). |
| **Metrik Evaluasi** | Metrik yang digunakan untuk mengevaluasi performa model adalah **binary crossentropy** dan **accuracy**. <br> 1. **Binary Crossentropy**: Mengukur kerugian (loss) antara label sebenarnya dan prediksi model. Rumusnya adalah: <br> $\[ \text{Binary Crossentropy} = -\frac{1}{N} \Sigma_{i=1}^N [y_i \log(p_i) + (1-y_i) \log(1-p_i)] \$] di mana $\( y_i \)$ adalah label sebenarnya, $\( p_i \)$ adalah probabilitas prediksi, dan $\( N \)$ adalah jumlah sampel. <br> 2. **Accuracy**: Mengukur persentase prediksi yang benar dari total prediksi yang dibuat. Rumusnya adalah: <br> $\[ \text{Accuracy} = \frac{\text{Number of Correct Predictions}}{\text{Total Number of Predictions}} \]$ Metrik ini memberikan gambaran umum tentang seberapa baik model dalam mengklasifikasikan input sebagai hoax dan fakta. |
| **Performa Model** | Model yang dibuat mencapai performa yang baik pada data uji dengan hasil sebagai berikut: <br> - **Loss**: 0.2798 <br> - **Accuracy**: 0.8961 <br> - **Validation Loss**: 0.6459 <br> - **Validation Accuracy**: 0.8118 <br><br> Berdasarkan performa yang ditunjukkan oleh model ini, dapat disimpulkan bahwa model memiliki kemampuan yang baik dalam memprediksi dan mengklasifikasikan berita antara hoax dan non-hoax, serta mampu menggeneralisasi dengan baik pada data validasi yang belum pernah dilihat sebelumnya. Namun, optimalisasi lebih lanjut pada hyperparameter atau arsitektur model mungkin dapat meningkatkan performa lebih lanjut.
| **Opsi deployment** | Proyek ini melakukan deployment menggunakan Railway, sebuah platform cloud untuk deployment aplikasi yang menyediakan kemudahan dalam mengelola infrastruktur aplikasi secara efisien. Railway memungkinkan untuk menjalankan aplikasi, memantau kinerja, dan memastikan ketersediaan model dengan lebih baik melalui integrasi yang mudah dengan alat monitoring seperti Grafana-Prometheus. |
| **Web app** | Model hoax detection telah di-deploy menggunakan Railway di [hoax-model-production.up.railway.app](https://hoax-model-production.up.railway.app/v1/models/hoax-model/metadata). Endpoint ini dapat diakses untuk melakukan prediksi terhadap teks untuk mendeteksi hoax.|
| **Monitoring** | Metrik yang Dimonitor <br> 1. **tensorflow:core:saved_model:read** <br> Metrik ini mencatat jumlah pembacaan (reads) yang dilakukan terhadap model SavedModel. Ini membantu dalam memahami seberapa sering model dimuat ulang atau diakses oleh TensorFlow Serving. <br> 2. **tensorflow:core** <br> Metrik ini menghitung jumlah eksekusi grafik yang terjadi saat TensorFlow Serving mengevaluasi atau melakukan prediksi dengan model. Ini mengindikasikan seberapa sering model aktif melakukan komputasi. <br> 3. **tensorflow:cc:saved_model** <br> Metrik ini mengukur waktu yang dibutuhkan untuk memuat model SavedModel ke dalam memori. Latensi yang rendah menunjukkan kinerja yang baik dalam memuat model. <br> 4. **tensorflow:serving** <br>Metrik ini mencatat jumlah total permintaan yang diterima oleh TensorFlow Serving. Ini memberikan gambaran tentang tingkat penggunaan dan beban kerja yang diterima oleh model. <br><br> Integrasi Grafana-Prometheus dengan TensorFlow Serving memungkinkan untuk memantau kinerja model serving secara efektif. Pemantauan metrik-metrik tersebut membantu dalam memahami penggunaan model dan kinerjanya, serta memungkinkan untuk melakukan optimasi yang diperlukan.|
